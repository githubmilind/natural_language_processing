2022-11-03 12:59:20,558 ----------------------------------------------------------------------------------------------------
2022-11-03 12:59:20,560 Model: "TextClassifier(
  (loss_function): CrossEntropyLoss()
  (document_embeddings): DocumentRNNEmbeddings(
    (embeddings): StackedEmbeddings(
      (list_embedding_0): FlairEmbeddings(
        (lm): LanguageModel(
          (drop): Dropout(p=0.25, inplace=False)
          (encoder): Embedding(275, 100)
          (rnn): LSTM(100, 1024)
          (decoder): Linear(in_features=1024, out_features=275, bias=True)
        )
      )
      (list_embedding_1): FlairEmbeddings(
        (lm): LanguageModel(
          (drop): Dropout(p=0.25, inplace=False)
          (encoder): Embedding(275, 100)
          (rnn): LSTM(100, 1024)
          (decoder): Linear(in_features=1024, out_features=275, bias=True)
        )
      )
    )
    (word_reprojection_map): Linear(in_features=2048, out_features=256, bias=True)
    (rnn): GRU(256, 512, batch_first=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (decoder): Linear(in_features=512, out_features=3, bias=True)
  (weights): None
  (weight_tensor) None
)"
2022-11-03 12:59:20,591 ----------------------------------------------------------------------------------------------------
2022-11-03 12:59:20,593 Corpus: "Corpus: 2801 train + 935 dev + 932 test sentences"
2022-11-03 12:59:20,595 ----------------------------------------------------------------------------------------------------
2022-11-03 12:59:20,597 Parameters:
2022-11-03 12:59:20,598  - learning_rate: "0.1"
2022-11-03 12:59:20,603  - mini_batch_size: "32"
2022-11-03 12:59:20,606  - patience: "3"
2022-11-03 12:59:20,608  - anneal_factor: "0.5"
2022-11-03 12:59:20,610  - max_epochs: "2"
2022-11-03 12:59:20,612  - shuffle: "True"
2022-11-03 12:59:20,615  - train_with_dev: "False"
2022-11-03 12:59:20,619  - batch_growth_annealing: "False"
2022-11-03 12:59:20,622 ----------------------------------------------------------------------------------------------------
2022-11-03 12:59:20,625 Model training base path: "data_fst"
2022-11-03 12:59:20,628 ----------------------------------------------------------------------------------------------------
2022-11-03 12:59:20,631 Device: cpu
2022-11-03 12:59:20,634 ----------------------------------------------------------------------------------------------------
2022-11-03 12:59:20,637 Embeddings storage mode: cpu
2022-11-03 12:59:20,643 ----------------------------------------------------------------------------------------------------
2022-11-03 13:00:48,806 epoch 1 - iter 8/88 - loss 0.01925580 - samples/sec: 8.77 - lr: 0.100000
2022-11-03 13:01:16,187 epoch 1 - iter 16/88 - loss 0.01703913 - samples/sec: 9.37 - lr: 0.100000
2022-11-03 13:01:58,756 epoch 1 - iter 24/88 - loss 0.01633629 - samples/sec: 6.02 - lr: 0.100000
2022-11-03 13:02:31,567 epoch 1 - iter 32/88 - loss 0.01639149 - samples/sec: 7.81 - lr: 0.100000
2022-11-03 13:03:00,881 epoch 1 - iter 40/88 - loss 0.01651442 - samples/sec: 8.75 - lr: 0.100000
2022-11-03 13:03:31,703 epoch 1 - iter 48/88 - loss 0.01633045 - samples/sec: 8.32 - lr: 0.100000
2022-11-03 13:03:53,686 epoch 1 - iter 56/88 - loss 0.01575028 - samples/sec: 11.66 - lr: 0.100000
2022-11-03 13:04:20,957 epoch 1 - iter 64/88 - loss 0.01558724 - samples/sec: 9.40 - lr: 0.100000
2022-11-03 13:04:48,219 epoch 1 - iter 72/88 - loss 0.01535619 - samples/sec: 9.61 - lr: 0.100000
2022-11-03 13:05:11,588 epoch 1 - iter 80/88 - loss 0.01536067 - samples/sec: 10.97 - lr: 0.100000
2022-11-03 13:05:32,941 epoch 1 - iter 88/88 - loss 0.01519224 - samples/sec: 12.00 - lr: 0.100000
2022-11-03 13:05:34,525 ----------------------------------------------------------------------------------------------------
2022-11-03 13:05:34,527 EPOCH 1 done: loss 0.0152 - lr 0.1000000
2022-11-03 13:07:33,046 DEV : loss 0.014456345699727535 - f1-score (micro avg)  0.8182
2022-11-03 13:07:34,060 BAD EPOCHS (no improvement): 0
2022-11-03 13:07:34,062 saving best model
2022-11-03 13:07:34,291 ----------------------------------------------------------------------------------------------------
2022-11-03 13:08:53,330 epoch 2 - iter 8/88 - loss 0.01488673 - samples/sec: 10.99 - lr: 0.100000
2022-11-03 13:09:14,721 epoch 2 - iter 16/88 - loss 0.01482444 - samples/sec: 11.98 - lr: 0.100000
2022-11-03 13:09:36,065 epoch 2 - iter 24/88 - loss 0.01451043 - samples/sec: 12.02 - lr: 0.100000
2022-11-03 13:10:01,906 epoch 2 - iter 32/88 - loss 0.01463183 - samples/sec: 9.92 - lr: 0.100000
2022-11-03 13:10:26,730 epoch 2 - iter 40/88 - loss 0.01461590 - samples/sec: 10.33 - lr: 0.100000
2022-11-03 13:10:49,840 epoch 2 - iter 48/88 - loss 0.01433767 - samples/sec: 11.10 - lr: 0.100000
2022-11-03 13:11:13,064 epoch 2 - iter 56/88 - loss 0.01395431 - samples/sec: 11.04 - lr: 0.100000
2022-11-03 13:11:35,199 epoch 2 - iter 64/88 - loss 0.01382092 - samples/sec: 11.59 - lr: 0.100000
2022-11-03 13:12:01,034 epoch 2 - iter 72/88 - loss 0.01362971 - samples/sec: 9.93 - lr: 0.100000
2022-11-03 13:12:24,143 epoch 2 - iter 80/88 - loss 0.01350738 - samples/sec: 11.09 - lr: 0.100000
2022-11-03 13:12:44,469 epoch 2 - iter 88/88 - loss 0.01361734 - samples/sec: 12.62 - lr: 0.100000
2022-11-03 13:12:46,029 ----------------------------------------------------------------------------------------------------
2022-11-03 13:12:46,031 EPOCH 2 done: loss 0.0136 - lr 0.1000000
2022-11-03 13:14:44,636 DEV : loss 0.017251277342438698 - f1-score (micro avg)  0.8182
2022-11-03 13:14:45,201 BAD EPOCHS (no improvement): 1
2022-11-03 13:14:45,313 ----------------------------------------------------------------------------------------------------
2022-11-03 13:14:45,316 loading file data_fst\best-model.pt
2022-11-03 13:16:40,616 0.8283	0.8283	0.8283	0.8283
2022-11-03 13:16:40,619 
Results:
- F-score (micro) 0.8283
- F-score (macro) 0.4531
- Accuracy 0.8283

By class:
               precision    recall  f1-score   support

    offensive     0.8283    1.0000    0.9061       772
non_offensive     0.0000    0.0000    0.0000       160

    micro avg     0.8283    0.8283    0.8283       932
    macro avg     0.4142    0.5000    0.4531       932
 weighted avg     0.6861    0.8283    0.7505       932
  samples avg     0.8283    0.8283    0.8283       932

2022-11-03 13:16:40,620 ----------------------------------------------------------------------------------------------------
