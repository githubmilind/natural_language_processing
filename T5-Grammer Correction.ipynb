{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9911f55",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f68ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from happytransformer import HappyTextToText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e09174b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f9920b9483485dbe82135e6cc27bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbb24cda65d4cc8b1cf012c9a14e526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558ca0fb59d64440a03d25be4abeedf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6c014819984ef0a50403fe100c5c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milind.DESKTOP-GBR1BS2\\miniconda3\\envs\\teststackoverflow\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:161: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  FutureWarning,\n",
      "05/16/2022 16:43:53 - INFO - happytransformer.happy_transformer -   Using model: cpu\n"
     ]
    }
   ],
   "source": [
    "happy_tt = HappyTextToText(\"T5\", \"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d71769b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/16/2022 16:44:03 - INFO - happytransformer.happy_transformer -   Using model: cpu\n"
     ]
    }
   ],
   "source": [
    "from happytransformer import HappyTextToText, TTSettings\n",
    "\n",
    "happy_tt = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")\n",
    "\n",
    "args = TTSettings(num_beams=5, min_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "079ed64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from happytransformer import HappyTextToText, TTSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bac98666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/16/2022 16:44:14 - INFO - happytransformer.happy_transformer -   Using model: cpu\n"
     ]
    }
   ],
   "source": [
    "happy_tt = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "994fc6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TTSettings(num_beams=5, min_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94a510d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = happy_tt.generate_text(\"grammar: This sentences has has bads grammar.\", args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eaa9e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sentence has bad grammar.\n"
     ]
    }
   ],
   "source": [
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09f898ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you again for the rates and roll your card.\n"
     ]
    }
   ],
   "source": [
    "result = happy_tt.generate_text(\"grammar: thank you so about the rates again and roll your card.\", args=args)\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f775f867",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e66f4cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83d67fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90991c0f298148458bffece01d6d5ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae8aadec877472bab41bc8c00436eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11863b55950a467e9ed4818e64adb9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8126bc736a4c45a848d63d479f3df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a3bbe87b4b486580f0176490070ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd0c7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fa5833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I'm a language model, I'm writing a new language for you. But first, I'd like to tell you about the language itself\"},\n",
       " {'generated_text': \"Hello, I'm a language model, and I'm trying to be as expressive as possible. In order to be expressive, it is necessary to know\"},\n",
       " {'generated_text': \"Hello, I'm a language model, so I don't get much of a license anymore, but I'm probably more familiar with other languages on that\"},\n",
       " {'generated_text': \"Hello, I'm a language model, a functional model... It's not me, it's me!\\n\\nI won't bore you with how\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not an object model.\\n\\nIn a nutshell, I need to give language model a set of properties that\"}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "303ac671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"thank you so about the rates again and roll your card out before it ships the second time around. It's a great way to get the cash back\"},\n",
       " {'generated_text': \"thank you so about the rates again and roll your card in. I'll write on Monday. I am working on an update to the new rules.\"},\n",
       " {'generated_text': 'thank you so about the rates again and roll your card over, all the way to the very end for good, very easy stuff! Thanks for your'},\n",
       " {'generated_text': 'thank you so about the rates again and roll your card, thank you so much!\"\\n\\nIt was nice to see our customers being so generous.'},\n",
       " {'generated_text': 'thank you so about the rates again and roll your card around till we have you,\" she replied and got down off her bike in his waiting SUV in'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"thank you so about the rates again and roll your card\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60bfa491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"thank you so about the rates again enrolling in the CPL program as long as you don't want to spend your whole college fund on a crappy\"},\n",
       " {'generated_text': \"thank you so about the rates again enrolling for the new exams! If anyone's interested, you can let me know, you're a really helpful\"},\n",
       " {'generated_text': \"thank you so about the rates again enrolling. It also looks like for our current model we're going to get a 2% rebate. It's\"},\n",
       " {'generated_text': 'thank you so about the rates again enrolling at a low rate and being told your next rate is a huge one. We have lots of fun making'},\n",
       " {'generated_text': 'thank you so about the rates again enrolling to the site right now and I am so glad you did. Thank you so much! (I have'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"thank you so about the rates again enroll\", max_length=30, num_return_sequences=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
